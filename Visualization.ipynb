{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization \n",
    "\n",
    "## TODO: k-NN + directed version (direction = style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"b57a0883-5514-4b6f-9e8e-bb7f6a18eef7\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      document.getElementById(\"b57a0883-5514-4b6f-9e8e-bb7f6a18eef7\").textContent = \"BokehJS successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"b57a0883-5514-4b6f-9e8e-bb7f6a18eef7\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'b57a0883-5514-4b6f-9e8e-bb7f6a18eef7' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"b57a0883-5514-4b6f-9e8e-bb7f6a18eef7\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"b57a0883-5514-4b6f-9e8e-bb7f6a18eef7\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_max : 30\n",
      "decoder_num_layers : 2\n",
      "beta_period : 100\n",
      "training_dir : logs/sentiment_input_deep\n",
      "epoches : 10000\n",
      "batch_size : 1048\n",
      "char2word_num_layers : 2\n",
      "initialize : True\n",
      "teacher_forcing : True\n",
      "learning_rate_change_rate : 3000\n",
      "beta_offset : 15\n",
      "encoder_num_layers : 1\n",
      "char2word_state_size : 512\n",
      "sequence_min : 8\n",
      "latent_dim : 16\n",
      "dtype_precision : 32\n",
      "cell : LSTM\n",
      "use_sentiment_feature : True\n",
      "initial_learning_rate : 0.001\n",
      "decoder_state_size : 1024\n",
      "output_keep_prob : 0.5\n",
      "acceptable_accuracy : 0.4\n",
      "peephole : True\n",
      "input_keep_prob : 0.9\n",
      "encoder_state_size : 1024\n",
      "latent_loss_weight : 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime \n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "output_notebook()\n",
    "\n",
    "import data_utils_LMR\n",
    "from data_utils_LMR import prepare_data,read_data, EncoderDecoder\n",
    "from model import Vrae as Vrae_model\n",
    "from batch import Generator\n",
    "\n",
    "training_dir = 'logs/'\n",
    "#training_dir += 'state1024_layers2_latent16_batch256_LSTM_seqs15-30_8e-3'\n",
    "#training_dir += 'state1024_layers2_latent16_batch256_LSTM_seqs15-30_8e-3_d0.5'\n",
    "#training_dir += state300_layers5_latent16_batch256_LSTM_seqs15-30_8e-3_B0.01_f32\n",
    "#training_dir += '6layers_UGRNN_small'\n",
    "#training_dir += '4layers_UGRNN'\n",
    "training_dir += 'sentiment_input_deep'\n",
    "\n",
    "# sentiment analyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentimentAnalyzer = SentimentIntensityAnalyzer()\n",
    "def getSentimentScore(sentence):\n",
    "    scores = sentimentAnalyzer.polarity_scores(sentence)\n",
    "    return (scores['neg'], scores['neu'] ,scores['pos'])\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "with open(training_dir +'/flags.json', 'r') as fp:\n",
    "    FLAGS = dotdict(json.loads( fp.read() ) )\n",
    "    \n",
    "for k,v in FLAGS.iteritems():\n",
    "    print k,':',v\n",
    "      \n",
    "n_samples = 5000#int(FLAGS.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from data_LMR/..\n",
      "Data already downloaded.\n",
      "Creating Vocabulary..\n",
      "Vocabulary already created.\n",
      "Converting sentences to sequences of ids..\n",
      "Moving some line from test set to train set..\n",
      "  reading data line 10000\n",
      "  reading data line 20000\n",
      "  reading data line 30000\n",
      "37109  sentences\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD9CAYAAABHnDf0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac80634b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(training_dir +'/training_parameters.json', 'r') as fp:\n",
    "    training_parameters = json.loads( fp.read() )\n",
    "# vocabulary encoder-decoder\n",
    "encoderDecoder = EncoderDecoder()\n",
    "num_symbols = encoderDecoder.vocabularySize()\n",
    "# prepare data\n",
    "prepare_data(1000)\n",
    "sentences, ratings = read_data( max_size=None, \n",
    "                               max_sentence_size=training_parameters['seq_max'],\n",
    "                               min_sentence_size=int(FLAGS.sequence_min), \n",
    "                               test=False) \n",
    "print len(sentences), \" sentences\"\n",
    "if len(sentences) < n_samples:\n",
    "    n_samples = len(sentences) - 1\n",
    "sns.distplot( [len(sent) for sent in sentences])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "space_symbol = encoderDecoder.encode(\"I am\")[1]\n",
    "word_delimiters = [ data_utils_LMR._EOS, data_utils_LMR._GO, space_symbol ]\n",
    "batch_gen = Generator(sentences, ratings, n_samples, word_delimiters)\n",
    "num_iters = FLAGS.epoches * batch_gen.iterations_per_epoch()\n",
    "# text decoder ( text <-> ids)\n",
    "encoderDecoder = EncoderDecoder()\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}, # do not use GPU for testing\n",
    "    )\n",
    "\n",
    "# load model\n",
    "vrae_model = Vrae_model(char2word_state_size = int(FLAGS.char2word_state_size), \n",
    "                     char2word_num_layers = int(FLAGS.char2word_num_layers), \n",
    "                     encoder_state_size = int(FLAGS.encoder_state_size), \n",
    "                     encoder_num_layers = int(FLAGS.encoder_num_layers), \n",
    "                     decoder_state_size = int(FLAGS.decoder_state_size), \n",
    "                     decoder_num_layers = int(FLAGS.decoder_num_layers), \n",
    "                          latent_dim=int(FLAGS.latent_dim),\n",
    "                         batch_size=n_samples,\n",
    "                         num_symbols=num_symbols,\n",
    "                        latent_loss_weight=float(FLAGS.latent_loss_weight),\n",
    "                         dtype_precision=FLAGS.dtype_precision,\n",
    "                        cell_type=FLAGS.cell, \n",
    "                        peephole=FLAGS.peephole,\n",
    "                        input_keep_prob=float(FLAGS.input_keep_prob),\n",
    "                        output_keep_prob=float(FLAGS.output_keep_prob),\n",
    "                      sentiment_feature = bool(FLAGS.use_sentiment_feature)\n",
    "                       )\n",
    "\n",
    "def zToXdecoded(session,z_sample,s_length):\n",
    "    x_reconstruct = vrae_model.zToX(session,z_sample,s_length)\n",
    "    return encoderDecoder.prettyDecode( np.argmax(x_reconstruct[0], axis= 1) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./logs/sentiment_input_deep/model.ckp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "#print train_dir\n",
    "np.random.seed(13)\n",
    "batch_gen.shuffle()\n",
    "samples = []\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    print\n",
    "    padded_batch_xs, batch_ys, batch_lengths, batch_weights, end_of_words, batch_word_lengths, max_length  = batch_gen.next_batch()\n",
    "    vaderSentiments = [ getSentimentScore(encoderDecoder.prettyDecode(xx)) for xx in padded_batch_xs]\n",
    "    x_reconstruct,z_vals,z_mean_val,z_log_sigma_sq_val, losses  = vrae_model.reconstruct( sess, \n",
    "                                                                                         padded_batch_xs,batch_lengths, \n",
    "                                                                                         batch_weights, \n",
    "                                                                                         end_of_words, \n",
    "                                                                                         batch_word_lengths,\n",
    "                                                                                        vaderSentiments)\n",
    "print \"Done!\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vaderSentiments = [ getSentimentScore(encoderDecoder.prettyDecode(padded_batch_xs[i])) for i in xrange(n_samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#np.random.seed(13)\n",
    "for i in range(10):\n",
    "    i = int(np.random.random()*n_samples)\n",
    "    i = i\n",
    "    print \"sentiment:\", vaderSentiments[i],\"| rating:\", batch_ys[i]\n",
    "    print encoderDecoder.prettyDecode( padded_batch_xs[i] )\n",
    "    print encoderDecoder.prettyDecode( np.argmax(x_reconstruct[i], axis= 1) )\n",
    "    print \"------------------------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction in the Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dimension reduction\n",
    "from sklearn.manifold import TSNE\n",
    "X = np.array(z_vals)\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "zs_reduced = model.fit_transform(X) \n",
    "xs = [ zs_reduced[i,0] for i in xrange(n_samples) ]\n",
    "ys = [ zs_reduced[i,1] for i in xrange(n_samples) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.layouts import column\n",
    "from bokeh.models import CustomJS, ColumnDataSource, Select\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "!export BOKEH_LOG_LEVEL=error\n",
    "output_file(\"latent_space.html\")\n",
    "\n",
    "inputs = [encoderDecoder.prettyDecode(x) for x in padded_batch_xs]\n",
    "M =max(batch_lengths)\n",
    "binary_rating = [ int(r > 5) for r in batch_ys]\n",
    "colors_sent = [ \"#%02x%02x%02x\" % ( 100 + 150 * r[0] ,  100 + 150 * r[2]  , 100 + 100 * r[1]  ) for r in vaderSentiments ]\n",
    "color_rating = [ \"#%02x%02x%02x\" % (255 * (1-r) , 100, 255*r) for r in binary_rating ]\n",
    "colors_lengths = [ \"#%02x%02x%02x\" % (  ( 255 * (float(r)/float(M))), 50, 255 - 255 * (float(r)/float(M)))  for r in batch_lengths ]\n",
    "hasQuestionMark = [ int(\"?\" in x) for x in inputs]\n",
    "colors_questionMark = [\"#%02x%02x%02x\" % (255 * (1-r) , 100, 255*r) for r in hasQuestionMark]\n",
    "is_past_voice = [ int(\"was\" in x) or int(\"were\" in x) or int(\"did\" in x) or int(\"had\" in x) for x in inputs]\n",
    "colors_past = [\"#%02x%02x%02x\" % (255 * (1-r) , 100, 255*r) for r in is_past_voice]\n",
    "\n",
    "source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x=xs,\n",
    "            y=ys,\n",
    "            input=inputs,\n",
    "            output= [encoderDecoder.prettyDecode(np.argmax(y, axis= 1) ) for y in x_reconstruct],\n",
    "            rating=batch_ys,\n",
    "            sent= vaderSentiments,\n",
    "            rating_color=color_rating,\n",
    "            sentiment_color=colors_sent,\n",
    "            lenght_color=colors_lengths,\n",
    "            questionMark_color=colors_questionMark,\n",
    "            past_color = colors_past,\n",
    "            lengths=batch_lengths,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"index\", \"$index\"),\n",
    "            (\"(x,y)\", \"($x, $y)\"),\n",
    "            (\"input\", \"@input\"),\n",
    "            (\"output\", \"@output\"),\n",
    "            (\"rating\", \"@rating\"),\n",
    "            (\"lengths\", \"@lengths\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "p = figure(plot_width=800, plot_height=600, tools=[hover],title=\"Latent space\")\n",
    "cir = p.circle('x', 'y', size=9, source=source, fill_color=\"sentiment_color\", alpha=0.8)\n",
    "\n",
    "callback = CustomJS(args=dict(cir=cir,source=source), code=\"\"\"\n",
    "        var selected_color = cb_obj.value;\n",
    "        selected_color = selected_color\n",
    "        console.log(selected_color);\n",
    "        cir.glyph.line_color.field = selected_color;\n",
    "        cir.glyph.fill_color.field = selected_color;\n",
    "        source.trigger(\"change\")\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "select = Select(title=\"Color:\", value=\"sentiment\", options=[\"sentiment_color\", \"rating_color\", \"lenght_color\", \"questionMark_color\", \"past_color\"], callback=callback)\n",
    "\n",
    "\n",
    "layout = column(select, p)\n",
    "\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cols = sns.color_palette()\n",
    "pos = []\n",
    "neg = []\n",
    "neu = []\n",
    "major_sent = np.argmax(vaderSentiments, axis = 1)\n",
    "for i in xrange(n_samples):\n",
    "    if major_sent[i] == 2:\n",
    "        pos.append( z_mean_val[i,:] )\n",
    "    elif major_sent[i] == 0:\n",
    "        neg.append( z_mean_val[i,:] )\n",
    "    else:\n",
    "        neu.append( z_mean_val[i,:] )\n",
    "\n",
    "print len(pos), \"positive sentences\"\n",
    "print len(neg), \"negative sentences\"\n",
    "print len(neu), \"neutral sentences\"\n",
    "\n",
    "pos = np.array(pos)\n",
    "neg = np.array(neg)\n",
    "neu = np.array(neu)\n",
    "\n",
    "side_lenght = int(np.sqrt(int(FLAGS.latent_dim)))\n",
    "if side_lenght**2 < int(FLAGS.latent_dim):\n",
    "    side_lenght +=1\n",
    "f, axs = plt.subplots(ncols=side_lenght, nrows=side_lenght, sharey=True, figsize=(10, 10))\n",
    "for i in xrange(side_lenght):\n",
    "    for j in xrange(side_lenght):\n",
    "        k = i*side_lenght+j\n",
    "        if k < int(FLAGS.latent_dim):\n",
    "            sns.distplot( neu[:,k], ax=axs[i,j], hist=False, color= cols[0] )\n",
    "            sns.distplot( pos[:,k], ax=axs[i,j], hist=False, color= cols[1] )\n",
    "            sns.distplot( neg[:,k], ax=axs[i,j], hist=False, color= cols[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Sentiment Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import random\n",
    "\n",
    "KLs = []\n",
    "for k in xrange(int(FLAGS.latent_dim)):\n",
    "    a = list(neg[:,k])\n",
    "    b = list(pos[:,k])\n",
    "    kl = np.abs( np.mean(a) - np.mean(b))\n",
    "    \n",
    "    KLs.append( kl )\n",
    "\n",
    "sorted_kls = sorted( enumerate(KLs) , key = lambda x: x[1], reverse=True )\n",
    "for k,kl in sorted_kls:\n",
    "    print k,kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=sorted_kls[0][0]\n",
    "sns.distplot( neu[:,k], hist=False, color= cols[0] )\n",
    "sns.distplot( pos[:,k], hist=False, color= cols[1] )\n",
    "sns.distplot( neg[:,k], hist=False, color= cols[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ks = sorted_kls[0][:3]\n",
    "dx = 2\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    u0 = \"I like this movie.\"\n",
    "    u1 = \"I recommend this movie.\"\n",
    "    u = u0\n",
    "    #print u\n",
    "    z0 = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(u), sentiment=getSentimentScore(u))[0]\n",
    "    #z0 = np.zeros(int(FLAGS.latent_dim))\n",
    "    dz = np.zeros(int(FLAGS.latent_dim))\n",
    "    dz[k] = dx\n",
    "    z1 = z0 + dz\n",
    "    z2 = z0 - dz\n",
    "    print \"distance between two points:\",np.linalg.norm(z2-z1),\"\\n\"\n",
    "    zs = []\n",
    "    for t in np.linspace(0,1,30):\n",
    "        zs.append( (1-t) * z1 + t * z2 )\n",
    "\n",
    "    for z_ in zs:\n",
    "        print zToXdecoded(sess, z_ , 45 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension pairplot\n",
    "\n",
    "cross check dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "major_sent = np.argmax(vaderSentiments, axis = 1)\n",
    "sent_df = pd.DataFrame( z_mean_val )\n",
    "sent_df['major_sent'] = major_sent\n",
    "#sns.pairplot(sent_df, hue='major_sent', diag_kind=\"kde\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous space: Homotopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    print\n",
    "    \n",
    "    # show interpolations\n",
    "    u0 = [\"I loved it.\" , \"I hated this film.\"]\n",
    "    u01 = [\"I loved it.\" , \"It was terrible.\"]\n",
    "    u1 = [\"I loved this movie!.\", \"I hated this movie!\"]\n",
    "    u2 = [\"The best movie I've seen!\", \"The worst movie ever made.\"]\n",
    "    u3 = [\"great movie.\", \"terrible movie.\"]\n",
    "    u4 = [\"that's actually pretty good.\" , \"That was a failure.\"]\n",
    "    u5 = [\"I didn't laugh at all.\", \"I wanted to love this movie.\"]\n",
    "    u6 = [\"so bad that it's really bad\" , \"Where is the acting?\"]\n",
    "    u7 = [\"I love old movies.\", \"I prefer old movies.\"]\n",
    "    u8 = [\"the music is very bad.\", \"the music is just awful.\"]\n",
    "    u9 = [\"awesome!\", \"terrible.\"]\n",
    "    u10 = [\"awful.\" , \"pretty worthless.\"]\n",
    "    u11 = [\"yes you do.\" , \"no you don't.\"]\n",
    "    u12 = [\"The acting was really bad.\" , \"The acting was really good!\"]\n",
    "    u13 = [\"This film was fascinatingly stupid.\" , \"This is an excellent film.\"]\n",
    "    u14 = [\"I don't recommend it to anyone.\", \"This is a really really bad movie.\"]\n",
    "    u = u10\n",
    "    z1 = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(u[0]),sentiment=getSentimentScore(u[0]))[0]\n",
    "    z2 = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(u[1]),sentiment=getSentimentScore(u[1]))[0]\n",
    "    #z1 = np.zeros(16)\n",
    "    #z2 = 0.1 * np.ones(16)\n",
    "    print \"distance between two points:\",np.linalg.norm(z2-z1),\"\\n\"\n",
    "    zs = []\n",
    "    for t in np.linspace(0,1,20):\n",
    "        zs.append( (1-t) * z1 + t * z2 )\n",
    "\n",
    "    for z_ in zs:\n",
    "        print zToXdecoded(sess, z_ , 45 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction: Reconstructing using Model's knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    u0 = \"I like this movie.\"\n",
    "    u1 = \"It was terrible.\"\n",
    "    u2 = \"I recommend it.\"\n",
    "    u3 = \"I loved it.\"\n",
    "    us = [u0,u1,u2,u3]\n",
    "    for u in us:\n",
    "        z = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(u), sentiment=getSentimentScore(u))[0]\n",
    "        print u, \"->\",\n",
    "        print zToXdecoded(sess,z,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    print\n",
    "    \n",
    "    # show interpolations\n",
    "    a = \"I liked it.\"\n",
    "    b = \"I didn't like it.\"\n",
    "    c = \"I recommend this movie.\"\n",
    "    \n",
    "    \n",
    "    #a = \"it was terrible.\"\n",
    "    #b = \"it was not good.\"\n",
    "    #c = \"Id didn't like it.\"\n",
    "    \n",
    "    #a = \"I love this movie!\"\n",
    "    #b = \"I like this movie.\"\n",
    "    #c = \"I love the acting!\"\n",
    "    \n",
    "    za = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(a), sentiment=getSentimentScore(a) )[0]\n",
    "    zb = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(b), sentiment=getSentimentScore(b))[0]\n",
    "    zc = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(c), sentiment=getSentimentScore(c))[0]\n",
    "    \n",
    "    # translation\n",
    "    zd = zc + (zb - za)\n",
    "    print \"a \\t\\t|\", a,\"|\", zToXdecoded(sess, za , 40 )\n",
    "    print \"b \\t\\t|\", b,\"|\", zToXdecoded(sess, zb , 40 )\n",
    "    print \"c \\t\\t|\", c,\"|\", zToXdecoded(sess, zc , 40 )\n",
    "    print\n",
    "    print \"c + b-a \\t|\", zToXdecoded(sess, zd , 40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    print\n",
    "    \n",
    "    # show interpolations\n",
    "    u1 = \"That's actually pretty good.\"\n",
    "    u2 = \"I love it.\"\n",
    "    u = u1\n",
    "    z1 = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(u), sentiment=getSentimentScore(u))[0]\n",
    "    print z1\n",
    "    print\n",
    "    r = 1\n",
    "    zs = []\n",
    "    for t in range(50):\n",
    "        z2 = [ z_ + r * np.random.random() for z_ in z1  ]\n",
    "        zs.append( z2)\n",
    "\n",
    "    for z_ in zs:\n",
    "        print zToXdecoded(sess, z_ , 40 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log p(x) =  \\sum_{i=1}^N q(z^{(i)} | x ) \\log p(x)$$\n",
    "\n",
    "\n",
    "$$ \\sum_{i=1}^N q(z^{(i)} | x ) \\left [    \\frac{q_\\phi(z^{(i)} | x) p_\\theta(x,z)}{p_\\theta(z|x^{(i)}) q_\\phi(z^{(i)} | x) }    \\right ] $$\n",
    "   \n",
    "   \n",
    "$$ \\sum_{i=1}^N q(z^{(i)} | x ) \\log \\frac{q(z^{(i)} | x )}{p_\\theta(z|x^{(i)})} + q(z^{(i)} | x ) \\log p_\\theta(x,z) - q(z^{(i)} | x ) log q(z^{(i)} | x ) $$\n",
    "\n",
    "\n",
    "$$ D_{KL} (q(z^{(i)} | x ) || p_\\theta(z|x^{(i)})) + E_{q(z^{(i)} | x )} [- \\log q(z^{(i)} | x ) + \\log p_\\theta (x,z)] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-199-5662f678ed41>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-199-5662f678ed41>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    & = \\sum_{i=1}^N q(z^{(i)} | x ) \\left [    \\frac{q_\\phi(z^{(i)} | x) p_\\theta(x,z)}{p_\\theta(z|x^{(i)}) q_\\phi(z^{(i)} | x) }    \\right ]  \\   & = \\sum_{i=1}^N q(z^{(i)} | x ) \\log \\frac{q(z^{(i)} | x )}{p_\\theta(z|x^{(i)})} + q(z^{(i)} | x ) \\log p_\\theta(x,z) - q(z^{(i)} | x ) log q(z^{(i)} | x ) \\   & = D_{KL} (q(z^{(i)} | x ) || p_\\theta(z|x^{(i)})) + E_{q(z^{(i)} | x )} [- \\log q(z^{(i)} | x ) + \\log p_\\theta (x,z)]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " & = \\sum_{i=1}^N q(z^{(i)} | x ) \\left [    \\frac{q_\\phi(z^{(i)} | x) p_\\theta(x,z)}{p_\\theta(z|x^{(i)}) q_\\phi(z^{(i)} | x) }    \\right ]  \\\\\n",
    "    & = \\sum_{i=1}^N q(z^{(i)} | x ) \\log \\frac{q(z^{(i)} | x )}{p_\\theta(z|x^{(i)})} + q(z^{(i)} | x ) \\log p_\\theta(x,z) - q(z^{(i)} | x ) log q(z^{(i)} | x ) \\\\\n",
    "    & = D_{KL} (q(z^{(i)} | x ) || p_\\theta(z|x^{(i)})) + E_{q(z^{(i)} | x )} [- \\log q(z^{(i)} | x ) + \\log p_\\theta (x,z)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathcal{L} (\\theta , \\phi ; \\theta^{(i)})  = E_{q_\\phi(z| x^{(i)} )} [- \\log q_\\phi( | x^{(i)} ) + \\log p_\\theta (x^{(i)},z)] $$\n",
    "\n",
    "$$- D_{KL} ( q_\\phi(z | x^{(i)} ) || p_\\theta(z) ) + E_{q_\\phi(z| x^{(i)} )} [ \\log p_\\theta(x^{(i)} | z)]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
